---
title: "SDG contributions"
format: html
---

```{r load data}
library(sparklyr)
library(ggplot2)
library(patchwork)
library(dplyr)
library(arrow)
library(here)
library(tidyr)
library(forcats)
library(readr)

theme_set(theme_bw())

source(here("R/helpers.R"))

Sys.setenv(SPARK_HOME = "/home/tklebel/spark-3.4.0-bin-hadoop3/")
Sys.setenv(HADOOP_HOME = "/home/hadoop/hadoop-3.3.1")
Sys.setenv(HADOOP_CONF_DIR = "/home/hadoop/hadoop-3.3.1/etc/hadoop")
Sys.setenv(YARN_HOME = "/home/hadoop/hadoop-3.3.1")
Sys.setenv(YARN_CONF_DIR = "/home/hadoop/hadoop-3.3.1/etc/hadoop")
Sys.setenv(JAVA_HOME="/usr/lib/jvm/java-1.11.0-openjdk-amd64")

config <- spark_config()
config$spark.executor.cores <- 5
config$spark.executor.instances <- 38
config$spark.executor.memory <- "20G"
config$spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version <- 2

sc <- spark_connect(master = "yarn", config = config,
                    app_name = "SDG-knowledge-production")

message("Connection to Spark successful!")

message("Reading the datasets...")

# Overall MAG data
paper_cols <- c("id", "rank", "doi", "type", "title_normalised", "title", 
                "unknown1", "year", "date", "unknown2", "publisher", 
                paste0("unknown", 3:12),
                "journal", paste0("unknown", c(14:16)))

mag_2021_papers <- spark_read_csv(sc, "/tklebel/mag-2021-03-15/Papers.txt",
                                  name = "mag2021_papers",
                                  memory = FALSE,
                                  delimiter = "\\t", header = FALSE,
                                  columns = paper_cols)

mag_2021_paper_author_affil <- spark_read_csv(
  sc, 
  "/tklebel/mag-2021-03-15/PaperAuthorAffiliations.txt",
  name = "mag2021_paper_author_affil", delimiter = "\\t",
  memory = FALSE, header = FALSE)

# SDG specific data
papers <- spark_read_csv(sc, "/tklebel/SDG/sdg_papers_collated.csv",
                         name = "papers")
sdg_labels <- spark_read_csv(sc, "/tklebel/SDG/sdg_labels.csv",
                             name = "sdg_labels")
# join the labels here, since we are doing everything by SDG
papers <- papers %>% 
  left_join(sdg_labels)

# remove 2020
papers <- papers %>% 
  filter(year < 2020)

# Affiliations
affils <- spark_read_csv(sc,
                         "/tklebel/SDG/affiliations_with_country_code.csv",
                         name = "affils")

author_paper_affiliations <- spark_read_csv(
  sc,
  "/tklebel/SDG/sdg_author_paper_affil.csv",
  name = "author_paper_affiliations"
)

# UN country information
un_countries <- read_csv2(here::here("data/external/UNSD â€” Methodology.csv"))

un_countries_selection <- un_countries %>% 
  select(country_code = `ISO-alpha3 Code`, country_name = `Country or Area`, 
         continent = `Region Name`, sub_continent = `Sub-region Name`)

```

# Sample size
```{r}
# total sample size
papers %>% 
  sdf_nrow()
```

```{r}
# per SDG
papers %>% 
  count(SDG_label)
```

```{r}
papers %>% 
  group_by(year) %>% 
  filter(year %in% c(2006, 2018)) %>% 
  count(SDG_label) %>% 
  arrange(SDG_label, year)
```




# Growth of literature
```{r sdg_count, fig.width=7, fig.height=4}
sdg_counts <- papers %>% 
  count(SDG_label, year) %>% 
  collect()

overall_count <- mag_2021_papers %>% 
  filter(year %in% 2006:2019) %>% 
  count(year, name = "overall_n") %>% 
  collect() %>% 
  mutate(year = as.integer(year))

merged_count <- sdg_counts %>% 
  left_join(overall_count) %>% 
  mutate(prop = n / overall_n)
  
merged_count %>% 
  drop_na() %>% 
  ggplot(aes(as_year(year), prop, colour = fix_sdg(SDG_label))) +
  geom_line() +
  geom_point() +
  colorspace::scale_color_discrete_qualitative() +
  scale_y_log10(labels = scales::comma,
                breaks = c(10e+3, 30e+3, 1e+5, 1e+6)) +
  labs(x = NULL, y = "# of publications", colour = NULL,
       title = "Development of SDG areas over time") 
```

Normalised by the overall number of papers in MAG, there is some growth for 
these literatures. 

```{r growth-rates}
growth_rate_data <- merged_count %>% 
  arrange(SDG_label, year) %>% 
  group_by(SDG_label) %>% 
  mutate(prop_change = prop / lag(prop),
         prop_change = replace_na(prop_change, 1),
         prop_change = prop_change - 1)

growth_rate_data %>% 
  ggplot(aes(as_year(year), prop_change, colour = fix_sdg(SDG_label))) +
  geom_line() +
  geom_point() +
  colorspace::scale_color_discrete_qualitative() +
  scale_y_continuous(labels = scales::percent) +
  labs(x = NULL, y = "Yearly growth rate relative to total papers in MAG",
       colour = NULL,
       title = "Development of SDG areas over time") +
  theme(legend.position = "top")
```



```{r}
growth_rate_data %>% 
  filter(year %in% c(2006, 2019)) %>% 
  summarise(overall_growth_factor = {overall_n / lag(overall_n)}[2],
            individual_growth_factor = {n / lag(n)}[2],
            individual_growth_rate = individual_growth_factor^(1/(2019-2006)) - 1,
            overall_growth_rate = overall_growth_factor^(1/(2019-2006)) - 1) %>% 
  knitr::kable()
  
```

# Continents over time
```{r}
author_paper_affiliations_w_groups <- make_author_groups(author_paper_affiliations)

papers_w_affils <- papers %>% 
  select(paperid, SDG_label, year, citations_norm) %>% 
  left_join(author_paper_affiliations_w_groups) %>% 
  right_join(affils) %>% 
  select(paperid, SDG_label, year, authorid, affiliationid, country,
         paper_author_cat, author_position, citations_norm)
```


```{r}
papers_per_country_fos_author_pos <- papers_w_affils %>% 
  group_by(country, year, SDG_label, author_position) %>% 
  summarise(n = n()) %>% 
  collect()

papers_per_country_fos_author_pos_country <- papers_per_country_fos_author_pos %>%
  left_join(un_countries_selection, by = c("country" = "country_code")) %>% 
  drop_na()

normalised_region_share_time <- papers_per_country_fos_author_pos_country %>% 
  group_by(SDG_label, year, sub_continent) %>% 
  summarise(nn = sum(n)) %>% 
  mutate(share = nn/sum(nn))
```

```{r sub_continents_over_time, fig.width=8.2, fig.height=4.4}
date_scale <- scale_x_date(breaks = as_year(c(2006, 2010, 2015, 2019)),
               date_labels = "%Y")
base_col = "grey80"

subset_countries <- filter(
  normalised_region_share_time, 
  sub_continent %in% c("Northern America", "Western Europe", "Northern Europe",
                       "Eastern Asia"
  ))

normalised_region_share_time %>% 
  ggplot(aes(as_year(year), share, group = sub_continent, colour = sub_continent)) +
  geom_line(colour = base_col) +
  geom_line(data = subset_countries) +
  geom_point(data = subset_countries, size = 1.2) +
  facet_wrap(vars(fix_sdg(SDG_label))) +
  date_scale +
  scale_y_continuous(labels = function(x) scales::percent(x, 1)) +
  colorspace::scale_color_discrete_qualitative() +
  theme(legend.position = "top") +
  labs(x = NULL, y = "% of publications from world region within SDGs",
       colour = NULL)
```

This is now equivalent to full counting, since all author positions are included.


Need a baseline across all of MAG. For this we need:

- all papers
- all paper author affils
- mapping between affil and country




```{r}
spark_disconnect(sc)
```

